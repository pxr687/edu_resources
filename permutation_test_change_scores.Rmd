---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.10.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Permuation tests with change scores

```{python}
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
```

This notebook will simulate a clinical trial where a placebo group and an active drug group are tested pre and post treatment. The tests will test the null hypothesis that there is no difference in the pre/post treatment change scores for each group. E.g. that the drug is no more effective than placebo.

The output of the cell below shows the simulated symptom severity scores before treatment, for each participant. E.g. before the placebo group have received the placebo treatment, and before the drug group have received the active drug treatment:

```{python}
# setting a sample size for the simulated groups
samp_size = 80

# creating simulated pre-treatment scores for the placebo group
placebo_before = np.random.normal(100, 15, samp_size).astype('int')

print('\nPlacebo group symptom severity scores BEFORE treatment:')
display(placebo_before)

# creating simulated pre-treatment scores for the drug group
drug_before = np.random.normal(100, 15, samp_size).astype('int')

print('\nDrug group symptom severity scores BEFORE treatment:')
display(drug_before)
```

The output of the cell below shows the symptom severity scores after treatment:

```{python}
# creating simulated post-treatment scores for the placebo group
placebo_after = np.random.normal(95, 15, samp_size).astype('int')

print('Placebo group scores AFTER treatment:')
display(placebo_after)


# creating simulated post-treatment scores for the drug group
drug_after = np.random.normal(85, 15, samp_size).astype('int')

print('Drug group scores AFTER treatment:')
display(drug_after)
```

The cells below show some graphical inspection of the data, using seaborn:

```{python}
import seaborn as sns

# plotting the pre/post treatment scores for each group
sns.boxplot(data = [placebo_before, placebo_after, drug_before, drug_after])
# labelling the axes
plt.xticks(np.arange(4), ['placebo_before', 'placebo_after', 'drug_before', 'drug_after'])
plt.ylabel('symptom severity');
```

In this instance, from graphical inspection it does look like the post-treatment syptom severity is lower for the drug group than for the placebo group. It's especially informative to look at the line in the center of each boxplot, which shows the median.


# Change scores

The output of the cell below shows the change scores for each group. Generally this is calculated by subtracting the pre-treatment scores from the post-treatment scores.

```{python}
# calculating the change scores for the placebo group
placebo_change = placebo_after - placebo_before
print('\nPlacebo group change scores:')
display(placebo_change)

# calculating the change scores for the drug group
drug_change = drug_after - drug_before
print('\nDrug group change scores:')
display(drug_change)
```

We can graphically inspect the change scores for each group, in the same way as for the raw scores:

```{python}
sns.boxplot(data = [placebo_change, drug_change])
plt.xticks(np.arange(2), ['placebo group', 'drug group'])
plt.ylabel('symptom severity pre/post treatment change');
```

It does look like the drug group generally have more negative change scores. This indicates a greater reduction in symptom severity in the drug group, relative to the placebo group.

We can check this further with some descriptive statistics:

```{python}
print('The mean change for the placebo group = ', np.mean(placebo_change))

print('The mean change for the drug group = ', np.mean(drug_change))
```

# Permutation testing the difference in mean change scores between the two groups

We can permutation test the difference in the mean change scores between the groups in a very similar way to the permutation test shown in: https://matthew-brett.github.io/cfd2020/permutation/permutation_and_t_test.html

This method shuffles the change scores themselves. We are also interested in the *direction* of the change, so there's another method, which uses the +/- signs of the change scores, which I'll show after this.

First, let's calculate the actual difference between the mean change score of each group:

```{python}
actual_diff = np.mean(placebo_change) - np.mean(drug_change)

print(actual_diff)
```

The permutation test is shown below:

```{python}
# adpated from https://matthew-brett.github.io/cfd2020/permutation/permutation_and_t_test.html

# count the number of participants in the placebo group
n_placebo = len(placebo_change)

# pool the change scores together
pooled = np.append(placebo_change, drug_change)

# set the number of iterations for the permutation test
n_iters = 10000

# create an array to store the fake differences in the mean change scores
fake_differences = np.zeros(n_iters)

# for 10,000 iterations, shuffle the change scores around, as if there is no difference between the groups (e.g. no difference
# between the direction or magnitude of the changes in each group)
for i in np.arange(n_iters):
    shuffled = np.random.permutation(pooled)
    
    # calculate the fake difference in the mean change scores between each group
    fake_differences[i] = np.mean(shuffled[:n_placebo]) - np.mean(shuffled[n_placebo:])
    
```

In the familar way, we can plot the simulate sampling distribution of the fake differences in mean change scores:

```{python}
plt.hist(fake_differences)
plt.title('Sampling distribution of difference of fake mean change scores');
```

Let's plot the actual difference in mean change scores, to see how likely/unlikely a difference of that size was, in the simulation.

```{python}
plt.hist(fake_differences)
plt.title('Sampling distribution of difference of fake mean change score')
plt.plot(actual_diff, 1, 'o', markersize = 10, label = 'actual difference in mean change score')
plt.legend();
```

We can also calculate a p-value, but calculating the proportion of fake mean differences which were as large or larger than the absolute value of the actual difference:

```{python}
p_value = np.count_nonzero(fake_differences >= np.abs(actual_diff))/len(fake_differences)

print(p_value)
```

# Permutation testing the difference in +/- proportions of the change scores, between the two groups

Another way of testing whether the drug is effective, is to look only at the direction of the changes in each group. In this instance (and it can get a bit confusing) a negative change is what we want, as we want symptom severity to decrease.

If the drug is not effective, we would expect roughly equal amounts of positive and negative change scores in the drug group.

If the drug is no more effective than the placebo, we would expect the distribution of postivie and negative change scores to be the same between the placebo and drug groups.

The placebo might be effective, because of the placebo effect. So we might expect more negative changes than positive changes in both groups. 

So both groups may have more negative changes than positive changes. But if the drug is more effective than the placebo, we would expect the proportion of negative changes to be higher in the drug group than the placebo group.

First, let's write a function to convert the actual change scores to a string, either `+` or `-`, depending on the sign of the change score:

```{python}
def change_score_to_sign(change_scores):
    
    # copy the input array, to avoid changing the original change scores
    change_scores_no_zeros = np.copy(change_scores)
    
    # there may be change scores of 0, which are neither positive nor negative
    # find any 0s in the input array, and with a 50/50 chance, replace them with either -1 or 1
    change_scores_no_zeros[np.where(change_scores_no_zeros == 0)] = np.random.choice([-1, 1])
    
    # take the input array, replace any positive values with `+` and any negative values with `-`
    output = np.where(change_scores_no_zeros > 0, '+', '-')
    
    return output
```

```{python}
# testing the function on the placebo change scores
change_score_to_sign(placebo_change)
```

```{python}
# running the function on the change scores of both groups, and storing the results as variables
placebo_change_signs = change_score_to_sign(placebo_change)

drug_change_signs = change_score_to_sign(drug_change)
```

```{python}
print('Signs of the change scores for the placebo group:')
display(placebo_change_signs)

print('Signs of the change scores for the drug group:')
display(drug_change_signs)
```

What we are interested in is whether the proportion of negative change scores differs between the placebo and drug group.

The proportions of negative change scores are calculated and plotted in the cell below:

```{python}
prop_neg_placebo = np.count_nonzero(placebo_change_signs == '-')/len(placebo_change_signs)

prop_neg_drug = np.count_nonzero(drug_change_signs == '-')/len(drug_change_signs)


plt.bar(['placebo group', 'drug group'], [prop_neg_placebo, prop_neg_drug], color = ['blue', 'red'])
plt.ylabel('Proportion of negative change scores');
```

It does appear that a greater proportion of the drug group had negative change scores, indicating a greater proportion of participants had less severe symptoms post-treatment.

We can calculate the difference in these proportions:

```{python}
actual_proportion_diff = prop_neg_placebo - prop_neg_drug

print('Difference in the proportion of negative change scores (placebo group - drug group) =',  actual_proportion_diff)
```

We can permutation test this by shuffling the `+` and `-` labels around, under the null hypothesis that there is no difference in the proportion of negative change scores in each group:

```{python}
# count the number of participants in the placebo group
n_placebo = len(placebo_change)

# pool the change score signs from each group
pooled = np.append(placebo_change_signs, drug_change_signs)

# set the number of iterations
n_iters = 10000

# create an array to store the fake proportion differences
fake_differences = np.zeros(n_iters)

# for 10,000 iterations...
for i in np.arange(n_iters):
    
    # shuffle the +/- change labels around
    shuffled = np.random.permutation(pooled)
    
    # create a fake placebo group from the shuffled labels
    fake_placebo_change_signs = shuffled[:n_placebo]
    
    # create a fake drug group from the shuffled labels
    fake_drug_change_signs = shuffled[n_placebo:]
    
    # caclulate the fake proportion of negative changes in the placebo group
    fake_prop_neg_placebo = np.count_nonzero(fake_placebo_change_signs == '-')/len(fake_placebo_change_signs)
    
    # caclulate the fake proportion of negative changes in the drug group
    fake_prop_neg_drug = np.count_nonzero(fake_drug_change_signs == '-')/len(fake_drug_change_signs)
    
    # store the fake proportion difference in the fake_differences array
    fake_differences[i] = fake_prop_neg_placebo - fake_prop_neg_drug

```

Again, we can plot the simulated sampling distribution, under the null hypothesis, of the difference in the proportion of negative change scores between the groups:

```{python}
plt.hist(fake_differences)
plt.title('Sampling distribution of difference of fake differences in the proportion of negative change scores')
plt.plot(actual_proportion_diff, 1, 'o',  markersize = 10, label = 'actual difference in proportion of negative change scores')
plt.legend();
```

And we can calculate a p-value in the familiar way:

```{python}
p_value = np.count_nonzero(fake_differences >= np.abs(actual_proportion_diff))/len(fake_differences)

print('p = ', p_value)
```

```{python}

```
